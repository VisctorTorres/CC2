{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyHnKzqdeP73"
   },
   "source": [
    "<img src=\"escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "    <h1> ILI286 - Computación Científica II</h1>\n",
    "    <h1> Tarea 1: Deflation y Matrices Sparse </h1> \n",
    "    <h3> Victor Torres Varas 201173076-3</h3>\n",
    "    <h4> victor.torresva@alumnos.usm.cl</h4>\n",
    "</center>\n",
    "<p>\n",
    "<center>Octubre 2019 - v1.0 </center>\n",
    "</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as sparse\n",
    "import time\n",
    "from scipy import sparse\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wosjMLgZeP79"
   },
   "source": [
    "## Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZH1FuvIebrD"
   },
   "source": [
    "Esta tarea tiene como objetivo aplicar los contenidos vistos en clase, respecto a métodos numéricos para obtener valores y vectores propios. Además, esta instancia servirá para recordar (o aprender) el uso de *Jupyter Notebook*, junto con las principales bibliotecas del curso: *Numpy* y *Scipy*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZxTtGo5FXNfa"
   },
   "source": [
    "## Sección 1: Algoritmo Deflation (30 puntos)\n",
    "\n",
    "Se discutió en clases que una de las principales propiedades que tienen las matrices simétricas es que\n",
    "\n",
    "* Sus valores propios son reales.\n",
    "* Sus vectores propios son ortogonales.\n",
    "\n",
    "Sabemos que por medio de *Power Iteration* e *Inverse Power Iteration*, podemos rescatar algunos de los valores propios y vectores propios. Mediante *Normalized Simultaneous Iteration* o *Unshifted QR*, podemos extraer todos los valores y vectores propios al mismo tiempo. Ahora veremos un método distinto para extraer los valores y vectores propios, uno por uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos una matriz $A \\in \\mathbb{R}^{n \\times n}$ simétrica cuyos valores propios son $\\lambda_i$ (por simplicidad, consideraremos que también son todos positivos) y sus vectores propios son $\\mathbf{v}_i$, para $i \\in \\{1, 2, \\dots, n\\}$. Considere además que $\\lambda_i > \\lambda_j$, para todo $i < j$, es decir, los valores propios están ordenados. Considere ahora la matriz $A_1$ definida como:\n",
    "\n",
    "$$\n",
    "    A_1 = A - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (5 puntos)** Demuestre que los vectores propios de $A$ también son los vectores propios de $A_1$. ¿Cuáles son los valores propios de $A_1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta: \n",
    "Como sabemos A es simetrica y ademas estan los valores propios ordenados lo que significa que tenemos el dominante \n",
    "primero en 1y todos positivos.\n",
    "Primero tomamos el vector propio dominante de A, que multiplicamos por $A_1$,\n",
    "$$\n",
    "    A_1 \\mathbf{v}_1 = (A - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T)\\mathbf{v}_1.\n",
    "$$\n",
    "$$\n",
    "    A_1 \\mathbf{v}_1 = A\\mathbf{v}_1 - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T\\mathbf{v}_1.\n",
    "$$\n",
    "Sabiendo que $\\mathbf{v}_1^T\\mathbf{v}_1 = 1.$\n",
    "$$\n",
    "    A_1 \\mathbf{v}_1 = 0.\n",
    "$$\n",
    "Por lo que v_1 es un vector propio de $A_1$ el cual tiene como valor propio el 0. Nos falta el resto, enntonces tomamos otro vector de A pero debe ser distinto de $v_1$, $v \\not = v_1$,\n",
    "$$\n",
    "    A_1 \\mathbf{v} = (A - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T)\\mathbf{v}.\n",
    "$$\n",
    "$$\n",
    "    A_1 \\mathbf{v} = A\\mathbf{v} - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T\\mathbf{v}.\n",
    "$$\n",
    "Sabiendo que $\\mathbf{v}_1^T\\mathbf{v} = 0.$\n",
    "$$\n",
    "    A_1 \\mathbf{v} = A\\mathbf{v}.\n",
    "$$\n",
    "\n",
    "Finalmente nos queda q el vector propio $v$ de $A_1$ que se asocia a los valores de A, es decir, mantiene los valores y vectores propios con excepción de $v_1$ que tiene valor propio 0. Pero el vector propio dominante cambia, en este caso seria para $A_1$ el segundo de $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (10 puntos)** El proceso anterior, denominado *Deflation*, puede repetirse iterativamente para construir un algoritmo iterativo que permita encontrar los valores y vectores propios en sucesión. El algoritmo, paso a paso, puede definirse como:\n",
    "\n",
    "1. Se define $A_0 = A$, $\\lambda_0 = 0$ y $\\mathbf{v}_0 = \\mathbf{0}$.\n",
    "2. Para $i \\in \\{1, 2, \\dots, n\\}$\n",
    "    1. Se define $A_i = A_{i-1} - \\lambda_{i-1}\\mathbf{v}_{i-1}\\,\\mathbf{v}_{i-1}^T$.\n",
    "    2. Se encuentra el valor y vector propio dominante de $A_{i}$, denotados por $\\lambda_{i}$ y $\\mathbf{v}_{i}$, respectivamente.\n",
    "3. Se retorna el conjunto $\\{\\lambda_1, \\lambda_2, \\dots, \\lambda_n\\}$ y $\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{n}\\}$.\n",
    "\n",
    "Implemente la función `deflation`, el cual aplicará el algoritmo *Deflation* mediante el uso de *Power Iteration*. Esta función debe recibir como parámetros:\n",
    "* La matriz $A$.\n",
    "* Un *initial guess* $\\mathbf{x}_0$.\n",
    "* Un número de iteraciones.\n",
    "\n",
    "La función debe retornar una lista con los valores propios encontrados y una lista de los vectores propios encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=12\n",
    "ev = 2/np.arange(1,n+1)\n",
    "np.random.seed(0)\n",
    "B = np.random.rand(n,n)\n",
    "#print(B)\n",
    "Q, R = np.linalg.qr(B)\n",
    "#print(Q)\n",
    "#print(R)\n",
    "A = np.dot(np.dot(Q.transpose(), np.diag(ev)),Q) #Q^-1 * ev * Q\n",
    "#print(A)\n",
    "\n",
    "#Power itaracion de jupyter notebook del curso\n",
    "def power_iteration(A, x, k, verbose=False):\n",
    "    \"\"\"\n",
    "    Program 12.1 Power iteration\n",
    "    Computes dominant eigenvector of square matrix\n",
    "    Input: matrix A, initial (nonzero) vector x, number of steps k\n",
    "    Output: dominant eigenvalue lam, eigenvector u\n",
    "    \"\"\"\n",
    "    if verbose: print(\"Power Iteration Method\\n%s\"%('='*80))\n",
    "    for j in range(k):\n",
    "        u = x/np.linalg.norm(x)\n",
    "        x = np.dot(A, u)\n",
    "        lam = np.dot(u, x) #not really necessary to compute it at each iteration\n",
    "        if verbose: print(\"k=%d, lambda=%+.3f, u=%s\"%(j,lam,str(u.T)))\n",
    "    u = x/np.linalg.norm(x)\n",
    "    if verbose: print(\"k=%d, lambda=%+.3f, u=%s\\n\"%(j+1,lam,str(u.T)))\n",
    "    return (lam, u)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute all the eigenvalues and eigenvectors using Deflation procedure.\n",
    "Input:\n",
    "A - (n x n matrix) Matrix to compute its eigenvalues and eigenvectors\n",
    "x0 - (array) Initial guess for Power Iteration\n",
    "it - (integer) Number of iteration for Power Iteration.\n",
    "Output:\n",
    "eig_values - (list) A list with the eigenvalues found by the algorithm\n",
    "eig_vectors - (list) A list with the eigenvectors found by the algorithm\n",
    "'''\n",
    "def deflation(A, x0, it):\n",
    "    k = it\n",
    "    eig_values = []\n",
    "    eig_vectors = []\n",
    "    for  i in range(0,it):\n",
    "        #print(\"Iteracion #\", i)\n",
    "        lam, u = power_iteration(A, x0, k, verbose=False)\n",
    "        eig_values.append(lam)\n",
    "        eig_vectors.append(u)\n",
    "        A = A - np.outer(np.dot(lam,u),u.transpose())\n",
    "    return eig_values, eig_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.983477417152032, 0.847023069920312, 0.7506289003447759, 0.3467499708439723]\n",
      "[array([-0.28209586, -0.17040548, -0.0284793 ,  0.01265423,  0.08288897,\n",
      "       -0.08997173,  0.23520642,  0.65603569, -0.03234983, -0.08583302,\n",
      "        0.5615199 , -0.25695115]), array([ 3.59029953e-01,  5.46225340e-01, -4.14383094e-01,  1.99796278e-02,\n",
      "       -8.25514091e-05,  3.26174044e-01,  3.03382201e-01, -5.93823583e-02,\n",
      "       -3.23502211e-01, -1.36527099e-01,  2.29911469e-01,  1.50045616e-01]), array([-0.11381304,  0.07331188,  0.44597933, -0.63024044,  0.05292362,\n",
      "       -0.16894893,  0.20404775,  0.01663173,  0.15143423,  0.36385857,\n",
      "        0.09098227,  0.38563128]), array([ 0.30805751, -0.12602325,  0.44822931,  0.66863346, -0.13251052,\n",
      "        0.18133157, -0.07731724,  0.19814061,  0.07880408,  0.01248307,\n",
      "        0.13643158,  0.34724802])]\n"
     ]
    }
   ],
   "source": [
    "it = 4\n",
    "x0 = np.ones(len(A))\n",
    "eig_values , eig_vectors = deflation(A,x0 ,it)\n",
    "print(eig_values)\n",
    "print(eig_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar su algoritmo, utilice la función `generate_matrix` que construye una matriz simétrica a partir de una lista de valores propios específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.07548328  0.52174915 -0.03599488  0.45237825]\n",
      " [ 0.52174915  0.93385553  0.25286136  0.35669185]\n",
      " [-0.03599488  0.25286136  0.71593696  0.06736024]\n",
      " [ 0.45237825  0.35669185  0.06736024  1.2026036 ]]\n",
      "[[-0.59461576  0.17362389  0.57806141 -0.53116085]\n",
      " [-0.52679521 -0.47732322  0.21638808  0.66919769]\n",
      " [-0.11984815 -0.76172908 -0.3703767  -0.51790571]\n",
      " [-0.59544549  0.40222642 -0.69414862  0.0426177 ]]\n",
      "[1.983477417152032, 0.847023069920312, 0.7506289003447759, 0.3467499708439723]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Given a list of n real vaues, returns a symmetric matrix whose eigenvalues are the given values.\n",
    "Input:\n",
    "eig_values - (list) list of n real values that will be used as eigenvalues\n",
    "Output: \n",
    "A - (n x n matrix) A symmetric matrix whose eigenvalues equals the values in eig_values list\n",
    "Q - (n x n matrix) An orthonormal matrix whose columns are the eigenvectors\n",
    "eig_values (list) A list with eigenvalues of A. It is the same list given as input.\n",
    "'''\n",
    "def generate_matrix(eig_values):\n",
    "    n = len(eig_values)\n",
    "    Q, _ = np.linalg.qr(np.random.rand(n, n))\n",
    "    L = np.diag(eig_values)\n",
    "    A = np.dot(Q, np.dot(L, Q.T))\n",
    "    return A, Q, eig_values\n",
    "\n",
    "\n",
    "A2, Q, eig_values = generate_matrix(eig_values)\n",
    "print(A2)\n",
    "print(Q)\n",
    "print(eig_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere matrices con los siguientes valores propios:\n",
    "* $\\{1, 2, \\dots, 10\\}$.\n",
    "* $\\{2, 2^2, 2^3, \\dots, 2^{12}\\}$.\n",
    "\n",
    "Utilice las matrices generadas para probar su algoritmo. Su tarea será probada con otras matrices, pero puede utilizar estas para verificar la correctitud de su algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.79324671 -0.17400742 -0.90114668 -1.35357138  0.76104211 -1.7022969\n",
      "  -0.15348536 -0.3038561  -0.57580074 -1.25186367]\n",
      " [-0.17400742  5.72227524 -0.36321186 -0.19449342 -0.07137248 -0.6033318\n",
      "  -0.3537302   0.64283577 -1.94357181  0.4390138 ]\n",
      " [-0.90114668 -0.36321186  5.70692139  0.72007207 -0.52182538  1.12512462\n",
      "  -0.47323057 -1.66984466 -0.00807752 -1.31349459]\n",
      " [-1.35357138 -0.19449342  0.72007207  5.29752895  0.77354893  0.12146796\n",
      "  -0.99413745  0.07709354 -0.444168   -0.44056365]\n",
      " [ 0.76104211 -0.07137248 -0.52182538  0.77354893  6.44979073 -0.46716364\n",
      "  -1.8066531  -0.20975758 -0.12715903 -1.8356868 ]\n",
      " [-1.7022969  -0.6033318   1.12512462  0.12146796 -0.46716364  5.01505097\n",
      "  -0.68763342 -1.58713102 -2.15354446  0.37460313]\n",
      " [-0.15348536 -0.3537302  -0.47323057 -0.99413745 -1.8066531  -0.68763342\n",
      "   3.90048432  1.07687474  0.01434994 -0.28328053]\n",
      " [-0.3038561   0.64283577 -1.66984466  0.07709354 -0.20975758 -1.58713102\n",
      "   1.07687474  6.81117232 -0.24948842 -0.50341759]\n",
      " [-0.57580074 -1.94357181 -0.00807752 -0.444168   -0.12715903 -2.15354446\n",
      "   0.01434994 -0.24948842  5.35472073  0.16120283]\n",
      " [-1.25186367  0.4390138  -1.31349459 -0.44056365 -1.8356868   0.37460313\n",
      "  -0.28328053 -0.50341759  0.16120283  4.94880864]]\n",
      "[[-0.38079664  0.02884315 -0.26618388 -0.44434693  0.01592725  0.15289849\n",
      "   0.57428372  0.05235046 -0.35317737  0.32396866]\n",
      " [-0.28448639 -0.19782195  0.13657288  0.20675297 -0.63689469 -0.06427145\n",
      "   0.13960541 -0.60633647  0.10374927  0.10426829]\n",
      " [-0.08992314  0.40343894 -0.34608126  0.13959213 -0.39430207  0.53205284\n",
      "  -0.06547277  0.12589098 -0.09289343 -0.47177738]\n",
      " [-0.217429   -0.02140831  0.16747426 -0.70721454 -0.11157804 -0.0617386\n",
      "  -0.55341855 -0.16368516 -0.16180679 -0.22036014]\n",
      " [-0.17024079  0.39348694  0.13288734  0.37526114  0.14954358 -0.29887058\n",
      "  -0.14406952 -0.16371383 -0.70511978  0.03559617]\n",
      " [-0.54072582 -0.28839421 -0.10453491  0.16423097  0.51311504  0.03361963\n",
      "   0.09636366 -0.20371778  0.13408862 -0.50334981]\n",
      " [-0.34342457  0.38350213  0.66688658  0.0249402   0.12302449  0.37457393\n",
      "   0.0264499   0.11490077  0.28136062  0.20277996]\n",
      " [-0.13865233  0.04764678 -0.46263547  0.11464428  0.21355589  0.27813215\n",
      "  -0.49060918 -0.26314007  0.15008917  0.5439669 ]\n",
      " [-0.47166582 -0.30682002 -0.04493502  0.20850406 -0.27931629 -0.20428148\n",
      "  -0.24832016  0.66047158 -0.02301626  0.14048438]\n",
      " [-0.19416483  0.56154024 -0.27073804 -0.12303919 -0.04217383 -0.57944059\n",
      "   0.08395183  0.00184681  0.46075725 -0.04069716]]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "#Matrices con valores propios {1,2....10}\n",
    "eig_values_1 = [1,2,3,4,5,6,7,8,9,10]\n",
    "A_1, Q, eig_values = generate_matrix(eig_values_1)\n",
    "print(A_1)\n",
    "print(Q)\n",
    "print(eig_values_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 244.22762006 -331.27065578  216.50135647 -243.57639403 -269.08552641\n",
      "   294.85203279  351.8361167    -3.66578162 -330.70028707   96.31796206\n",
      "    75.82063121  156.58497309]\n",
      " [-331.27065578  845.57849466  -21.87717788  -82.22538602  310.22635367\n",
      "  -824.73032438 -336.18296678   54.93821967  398.03275566 -302.74738876\n",
      "    14.29256276 -254.65625931]\n",
      " [ 216.50135647  -21.87717788 1026.14640555 -860.82136326 -434.16349079\n",
      "    67.16811253  678.7859626   468.14571154 -787.0269554  -206.52009503\n",
      "  -173.67828119  471.13101331]\n",
      " [-243.57639403  -82.22538602 -860.82136326 1012.81988658  499.35558795\n",
      "   143.92787637 -756.00538302 -236.56827669  620.55194156  155.49290106\n",
      "  -142.39301318 -283.30608805]\n",
      " [-269.08552641  310.22635367 -434.16349079  499.35558795  441.08085756\n",
      "  -241.13399669 -534.88951437  -77.28148689  452.95893878  -72.12001223\n",
      "  -120.19710151 -219.7352617 ]\n",
      " [ 294.85203279 -824.73032438   67.16811253  143.92787637 -241.13399669\n",
      "  1006.2911962   324.79599799   59.94927218 -484.16181659  221.70247698\n",
      "  -157.10571202  294.82882364]\n",
      " [ 351.8361167  -336.18296678  678.7859626  -756.00538302 -534.88951437\n",
      "   324.79599799  783.57672095  165.19927029 -694.06740151    8.45307105\n",
      "   104.99437248  332.26515589]\n",
      " [  -3.66578162   54.93821967  468.14571154 -236.56827669  -77.28148689\n",
      "    59.94927218  165.19927029  361.39070483 -335.48568232 -165.8609234\n",
      "  -275.86120958  253.67676259]\n",
      " [-330.70028707  398.03275566 -787.0269554   620.55194156  452.95893878\n",
      "  -484.16181659 -694.06740151 -335.48568232  837.27239893   38.97673728\n",
      "   142.5730794  -470.80748872]\n",
      " [  96.31796206 -302.74738876 -206.52009503  155.49290106  -72.12001223\n",
      "   221.70247698    8.45307105 -165.8609234    38.97673728  193.0703617\n",
      "    98.27867544  -29.38988352]\n",
      " [  75.82063121   14.29256276 -173.67828119 -142.39301318 -120.19710151\n",
      "  -157.10571202  104.99437248 -275.86120958  142.5730794    98.27867544\n",
      "   369.10187495 -184.79272618]\n",
      " [ 156.58497309 -254.65625931  471.13101331 -283.30608805 -219.7352617\n",
      "   294.82882364  332.26515589  253.67676259 -470.80748872  -29.38988352\n",
      "  -184.79272618  335.44347803]]\n",
      "[[-0.13375403  0.02582119  0.15708565 -0.65219761  0.36995701  0.44955612\n",
      "   0.07391293  0.00720481 -0.31506214 -0.18370002  0.13620329  0.18804358]\n",
      " [-0.18781028 -0.48112295  0.30683888 -0.01260389  0.25431667 -0.01255563\n",
      "  -0.39738703  0.23575704  0.00070728  0.07943517 -0.55771162 -0.20797574]\n",
      " [-0.19285021  0.03500174 -0.52747104 -0.10684464  0.15529168  0.04786692\n",
      "   0.20651926  0.38564474  0.35750977  0.21382205 -0.29947693  0.43697121]\n",
      " [-0.0543419  -0.50733097 -0.4467163  -0.00419223  0.3233686   0.03796327\n",
      "   0.1117983  -0.199329   -0.01585311  0.29259935  0.37985846 -0.38947618]\n",
      " [-0.40298825  0.26107895 -0.18374817  0.06071444 -0.41042251  0.56312225\n",
      "  -0.28240069  0.03310507 -0.10892545  0.26967341 -0.0329093  -0.2826972 ]\n",
      " [-0.15013756  0.01706742  0.15299718 -0.11812771  0.02528021 -0.21440811\n",
      "  -0.55924863  0.26940273  0.27267509  0.17668507  0.59268141  0.22587111]\n",
      " [-0.03157288 -0.41835391 -0.36784709 -0.00684515 -0.37114719 -0.11301543\n",
      "  -0.27925471 -0.07452218 -0.46493086 -0.2633085  -0.02113863  0.4106415 ]\n",
      " [-0.44419907  0.2472062   0.0775989  -0.05137556  0.1537037  -0.44401696\n",
      "   0.03455728 -0.41782086 -0.31775131  0.43507263 -0.14010562  0.16274894]\n",
      " [-0.15417425  0.02140778 -0.10939925 -0.59554319 -0.36105903 -0.43367661\n",
      "   0.15343215  0.22293883  0.04999643 -0.14620214 -0.04063516 -0.43809134]\n",
      " [-0.5020977  -0.10071485  0.18272311  0.40523854  0.02842488 -0.04881133\n",
      "   0.40078248  0.45682623 -0.26015848 -0.1994118   0.24500601 -0.01287015]\n",
      " [-0.47637104  0.02891148 -0.11397474  0.07273585  0.13494326  0.00686599\n",
      "  -0.13047058 -0.42422285  0.43767933 -0.58776576 -0.02488461 -0.03253554]\n",
      " [-0.14367068 -0.43957033  0.38280815 -0.13615758 -0.43580961  0.17465126\n",
      "   0.32953633 -0.25249601  0.32799765  0.24380417  0.04121202  0.24403446]]\n",
      "[2, 4, 8, 16, 32, 64, 128, 16, 18, 1024, 2048, 4096]\n"
     ]
    }
   ],
   "source": [
    "#Matrices con valores propios {2,2^2....2^10}\n",
    "eig_values_2 = [2**1, 2**2 , 2**3 , 2**4 , 2**5 , 2**6 , 2**7 , 2*8 , 2*9 , 2**10,2**11,2**12]\n",
    "A_2, Q, eig_values = generate_matrix(eig_values_2)\n",
    "print(A_2)\n",
    "print(Q)\n",
    "print(eig_values_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (15 puntos)** Implemente el algoritmo *Normalized Simultaneous Iteration* (NSI). Genere matrices de los siguientes tamaños, utilizando la función `generate_matrix`:\n",
    "\n",
    "* $100 \\times 100$.\n",
    "* $1000 \\times 1000$.\n",
    "* $10000 \\times 10000$.\n",
    "* $15000 \\times 15000$.\n",
    "\n",
    "Estime teóricamente cuanta memoria requiere cada uno de los algoritmos. Además, ejecute ambos algoritmos sobre las matrices generadas y mida el tiempo de ejecución. Concluya respecto a los resultados.\n",
    "##Conclusion##\n",
    "Al ser la matrices tan grandes los tiempos de ejecucion se volvieron sumamente altos a tal nivel que para NSI no pude obtenerlos y el kernel se exploto. En ese sentido se debe a que este ultimo utiliza QR por lo que la descomposicion crea matrices de dimesiones muy altas y usa una distinta en cada iteracion, lo que vuelve una constante creacion de matrices logrando asi ocupar mucho espacio.\n",
    "\n",
    "Respecto a la estimacion de cuanta memoria se requiere claramente notamos una gran diferencia estre sparses y no sparses, esto debido al tamaño de las matrices. Como se hace uso de las matrices varias veces y es necesario guardarlas para volver a utlizarlas, además de la descomposicion de estas, el tamaño se vuelve mucho más grande que el calculado, pero claramente el uso de NSI aumenta mucho el uso de memoria, llegando hasta los 2GB, donde un computador normal tiene 8GB, donde debemos descontar el S.O. lo que nos da un uso aprox de 5GB restantes. Por lo que podriamos almacenar en el mejor de los casos una matriz no sparse de 15000x15000 unas 3 veces y luego no tendremos mas memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño para 15000 1716.61 MB\n",
      "Tamaño para 10000 762.94 MB\n",
      "Tamaño para 1000 7.63 MB\n",
      "Tamaño para 100 0.08 MB\n"
     ]
    }
   ],
   "source": [
    "#Matrices No sparses\n",
    "from scipy.stats import uniform\n",
    "data = uniform.rvs(size=15000*15000, loc = 0, scale=2)\n",
    "data = np.reshape(data, (15000, 15000))\n",
    "data_size = data.nbytes/(1024**2)\n",
    "print('Tamaño para 15000 '+ '%3.2f' %data_size + ' MB')\n",
    "data = uniform.rvs(size=10000*10000, loc = 0, scale=2)\n",
    "data = np.reshape(data, (10000, 10000))\n",
    "data_size = data.nbytes/(1024**2)\n",
    "print('Tamaño para 10000 '+ '%3.2f' %data_size + ' MB')\n",
    "data = uniform.rvs(size=1000*1000, loc = 0, scale=2)\n",
    "data = np.reshape(data, (1000, 1000))\n",
    "data_size = data.nbytes/(1024**2)\n",
    "print('Tamaño para 1000 '+ '%3.2f' %data_size + ' MB')\n",
    "data = uniform.rvs(size=100*100, loc = 0, scale=2)\n",
    "data = np.reshape(data, (100, 100))\n",
    "data_size = data.nbytes/(1024**2)\n",
    "print('Tamaño para 100 '+ '%3.2f' %data_size + ' MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño para 100 Sparse0.01 MB\n",
      "Tamaño para 1000 Sparse0.95 MB\n",
      "Tamaño para 10000 Sparse95.37 MB\n",
      "Tamaño para 15000 Sparse214.58 MB\n"
     ]
    }
   ],
   "source": [
    "#Matrices Sparce\n",
    "data = uniform.rvs(size=100*100, loc = 0, scale=2)\n",
    "data = np.reshape(data, (100, 100))\n",
    "data_csr = sparse.csr_matrix(data)\n",
    "data_csr_size = data_csr.data.size/(1024**2)\n",
    "print('Tamaño para 100 Sparse '+ '%3.2f' %data_csr_size + ' MB')\n",
    "\n",
    "data = uniform.rvs(size=1000*1000, loc = 0, scale=2)\n",
    "data = np.reshape(data, (1000, 1000))\n",
    "data_csr = sparse.csr_matrix(data)\n",
    "data_csr_size = data_csr.data.size/(1024**2)\n",
    "print('Tamaño para 1000 Sparse '+ '%3.2f' %data_csr_size + ' MB')\n",
    "\n",
    "data = uniform.rvs(size=10000*10000, loc = 0, scale=2)\n",
    "data = np.reshape(data, (10000, 10000))\n",
    "data_csr = sparse.csr_matrix(data)\n",
    "data_csr_size = data_csr.data.size/(1024**2)\n",
    "print('Tamaño para 10000 Sparse '+ '%3.2f' %data_csr_size + ' MB')\n",
    "\n",
    "data = uniform.rvs(size=15000*15000, loc = 0, scale=2)\n",
    "data = np.reshape(data, (15000, 15000))\n",
    "data_csr = sparse.csr_matrix(data)\n",
    "data_csr_size = data_csr.data.size/(1024**2)\n",
    "print('Tamaño para 15000 Sparse '+ '%3.2f' %data_csr_size + ' MB')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsi(A, it):\n",
    "    n = np.size(A[0])\n",
    "    V = np.random.random(n*n).reshape(n,n)\n",
    "    Q,R = np.linalg.qr(V)\n",
    "    for i in range(it):\n",
    "        Z = np.outer(A,Q)\n",
    "        Q2,R2 = np.linalg.qr(Z)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos las matrices de los tamaños pedidos\n",
    "eig_values_1 = np.random.random(100)\n",
    "B_1, Q_1, eig_values_1 = generate_matrix(eig_values_1)\n",
    "eig_values_2 = np.random.random(1000)\n",
    "B_2, Q_2, eig_values_2 = generate_matrix(eig_values_2)\n",
    "eig_values_3 = np.random.random(10000)\n",
    "B_3, Q_3, eig_values_3 = generate_matrix(eig_values_3)\n",
    "eig_values_4 = np.random.random(15000)\n",
    "B_4, Q_4, eig_values_4 = generate_matrix(eig_values_4)\n",
    "\n",
    "#B_1 = np.random.random([100,100])\n",
    "#B_2 = np.random.random([1000,1000])\n",
    "#B_3 = np.random.random([10000,10000])\n",
    "#B_4 = np.random.random([15000,15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos el tamaño de las matrices\n",
    "print(B_1.shape,B_2.shape,B_3.shape,B_4.shape)\n",
    "\n",
    "##Los tiempos fueron muy altos por lo que no pude comprobar las dimensiones##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Tiempo de ejecucion B_1-------\n",
      " 0.0021219253540039062\n",
      "----------Tiempo de ejecucion B_2-------\n",
      " 0.21138930320739746\n",
      "----------Tiempo de ejecucion B_3-------\n",
      " 26.49055004119873\n",
      "----------Tiempo de ejecucion B_4-------\n",
      " 501.620600938797\n"
     ]
    }
   ],
   "source": [
    "#Para los tiempos de ejecucion para deflation\n",
    "#Probando el algoritmo\n",
    "it = 4\n",
    "x0 = np.ones(len(B_1))\n",
    "x1 = np.ones(len(B_2))\n",
    "x2 = np.ones(len(B_3))\n",
    "x3 = np.ones(len(B_4))\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "eig_values_1 , eig_vectors_1 = deflation(B_1,x0 ,it)\n",
    "elapsed_time = time() - start_time\n",
    "print(\"----------Tiempo de ejecucion B_1-------\\n\",elapsed_time)\n",
    "start_time = time()\n",
    "eig_values_2 , eig_vectors_2 = deflation(B_2,x1 ,it)\n",
    "elapsed_time = time() - start_time\n",
    "print(\"----------Tiempo de ejecucion B_2-------\\n\",elapsed_time)\n",
    "start_time = time()\n",
    "eig_values_3 , eig_vectors_3 = deflation(B_3,x2 ,it)\n",
    "elapsed_time = time() - start_time\n",
    "print(\"----------Tiempo de ejecucion B_3-------\\n\",elapsed_time)\n",
    "start_time = time()\n",
    "eig_values_4 , eig_vectors_4 = deflation(B_4,x3 ,it)\n",
    "elapsed_time = time() - start_time\n",
    "print(\"----------Tiempo de ejecucion B_4-------\\n\",elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Tiempo de ejecucion B_1-------\n",
      " 326.5782608985901\n"
     ]
    }
   ],
   "source": [
    "#Para los tiempos de ejecucion para NSI\n",
    "#Probando el algoritmo\n",
    "it = 4\n",
    "\n",
    "start_time = time()\n",
    "nsi(B_1,it)\n",
    "elapsed_time = time() - start_time\n",
    "print(\"----------Tiempo de ejecucion B_1-------\\n\",elapsed_time)\n",
    "start_time = time()\n",
    "nsi(B_2,it)\n",
    "elapsed_time = time() - start_time\n",
    "print(\"----------Tiempo de ejecucion B_2-------\\n\",elapsed_time)\n",
    "start_time = time()\n",
    "nsi(B_3,it)\n",
    "elapsed_time = time() - start_time\n",
    "print(\"----------Tiempo de ejecucion B_3-------\\n\",elapsed_time)\n",
    "start_time = time()\n",
    "nsi(b_4,it)\n",
    "elapsed_time = time() - start_time\n",
    "print(\"----------Tiempo de ejecucion B_4-------\\n\",elapsed_time)\n",
    "##La Memoria no dio y el kernel se reiniciaba##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2: Uso de matrices *Sparse* (60 puntos)\n",
    "\n",
    "Cuando una matriz es de tipo *Sparse*[1], es posible trabajar sobre matrices de mayor tamaño, debido a que se evita el almacenamiento de valores *innecesarios* (en este caso, los ceros)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (5 puntos)** Implemente la función `read_sparse_matrix` que reciba la ruta a un archivo de texto plano que contiene una matriz *sparse*, y construya la matriz respectiva utilizando una estructura de datos especializada para matrices *sparse*[2]. El formato del archivo será:\n",
    "* La primera línea del archivo contendrá un solo número `N`, donde `N` indica el tamaño de la matriz (matriz de tamaño `N`$\\times$`N`).\n",
    "* Cada una de las siguientes líneas contiene 3 números separados por espacios, que indicarán las entradas no nulas de la matriz. Si la línea contiene los números `i j a`, esto indica que en la fila `i` y columna `j`, la matriz tiene un coeficiente con valor `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para implementar el algoritmo y aprovechar que esta es sparse usaremos la libreria de scipy.sparse\n",
    "#leeremos el archivo que se nos da, de esta forma ahorramos espacio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read a file in the specified format to build a Sparse Matrix.\n",
    "Input:\n",
    "path - (string) A path to a file.\n",
    "Output:\n",
    "A - (N x N matrix) The matrix in a sparse format.\n",
    "'''\n",
    "def read_sparse_matrix(path):\n",
    "    #Primero abrimos el archivo que contiene la matriz sparse\n",
    "    file = open(path,\"r\")\n",
    "    #La primera linea corresponde al tamaño de la matriz, por lo que usamos readline()\n",
    "    n = int(file.readline())\n",
    "    row , col , k = [],[],[]\n",
    "    #Luego avanzamos en las lineas restantes que contienen la forma (row col k), es necesario separar cada uno para invocar \n",
    "    #la funcion csr_matriz la cual nos va formar la matriz sparse\n",
    "    for i in file:\n",
    "        auxr, auxc , auxk = i.split()\n",
    "        row.append(float(auxr))\n",
    "        col.append(float(auxc))\n",
    "        k.append(float(auxk))\n",
    "        #Ya separadas las posiciones y los valores realizamos la llamada a csr_matriz para formar la matriz Sparse\n",
    "    return sparse.csc_matrix((k,(row,col)),shape=(n,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargue las matrices adjuntas en los archivos `matrix_10000.txt`, `matrix_20000.txt` y `matrix_50000.txt`, de dimensiones $10000 \\times 10000$, $20000 \\times 20000$ y $50000\\times50000$ respectivamente, utlizando la función `read_sparse_matrix`. Considerando *double precision* para los números de punto flotante, indique cuánta memoria utilizarían estas matrices si fuesen cargadas utilizando arreglos bidimensionales o estructuras no-especializadas para matrices *sparse*. ¿Existe alguna diferencia al utilizar las estructuras de datos *sparse*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se vio mas arriba en el calculo de memoria, existe una clara diferencia en el uso de memoria, por lo que utilizar matrices sparse disminuye la memoria usada. Sparce trabaja solo con datos que no son nulos, es decir, permite que se libere espacio, lo que ayuda a que no se almacenen datos innecesarios como lo hacen las matrices no-sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"matrix_10000.txt\"\n",
    "path2 = \"matrix_20000.txt\"\n",
    "path3 = \"matrix_50000.txt\"\n",
    "MatrizSparceA = read_sparse_matrix(path1)\n",
    "MatrizSparceB = read_sparse_matrix(path2)\n",
    "MatrizSparceC = read_sparse_matrix(path3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (25 puntos)** Suponga ahora que la matriz simétrica $A$ en el algoritmo de *Deflation* es *Sparse*. Notar que luego de calcular el valor y vector propio dominante de $A$, el resultado obtenido para calcular $A_1$:\n",
    "\n",
    "$$\n",
    "    A_1 = A - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T,\n",
    "$$\n",
    "\n",
    "**no** necesariamente es una matriz *sparse*. Esto se debe a que la matriz $\\mathbf{v}_1\\mathbf{v}_1^T$ no necesariamente es *sparse* y al restarse con $A$, esta propiedad puede perderse.\n",
    "\n",
    "A pesar de lo anterior, una propiedad importante de *Power Iteration* es que no opera direcamente sobre la matriz, si no que solo es requerida a través del producto **matriz-vector**. Notar que si se desea calcular $A_1\\mathbf{u}$, donde $\\mathbf{u}$ es un vector arbitrario, puede calcularse como\n",
    "\n",
    "$$\n",
    "    A_1\\mathbf{u} \n",
    "    = \\left(A - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T\\right)\\mathbf{u}\n",
    "    = A\\mathbf{u} - \\lambda_1 \\mathbf{v}_1 \\left(\\mathbf{v}_1^T\\mathbf{u}\\right).\n",
    "$$\n",
    "\n",
    "De esta manera, no es necesario construir explícitamente la matriz $\\mathbf{v}_1\\mathbf{v}_1^T$. De manera general, la matriz $A_i\\mathbf{u}$ puede calcularse como\n",
    "\n",
    "$$\n",
    "    A_i\\mathbf{u} = A\\mathbf{u} - \\sum_{k = 1}^{i}\\lambda_k \\left( \\mathbf{v}_k^T\\mathbf{u} \\right) \\mathbf{v}_k.\n",
    "$$\n",
    "\n",
    "Implemente la función `A_times_vector` que reciba como parámetros: \n",
    "\n",
    "* Una matriz de tipo *sparse*.\n",
    "* Un entero $k$.\n",
    "* Una lista con $k$ valores propios.\n",
    "* Una lista con $k$ vectores propios.\n",
    "* Un vector $\\mathbf{u}$, arbitrario.\n",
    "\n",
    "La función debe retornar el resultado numérico del producto matriz-vector $A_{k}\\mathbf{u}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implementation of a Deflation matriz-vector product to avoid building non-sparse matrix\n",
    "Input:\n",
    "A - (N x N matrix) A matrix in a sparse format.\n",
    "k - (integer) An integer.\n",
    "k_eig_values - (list) A list with k eigenvalues of A.\n",
    "k_eig_vectors - (list) A list with k eigenvectors of A.\n",
    "u - (array) An arbitrary vector\n",
    "Output:\n",
    "b - (array) The result of a Deflation matrix times u, using the given eigenvalues and eigenvectors.\n",
    "'''\n",
    "\n",
    "#Usamos un vector arbitrario u\n",
    "k=10000\n",
    "u = np.random.random(k)\n",
    "\n",
    "def A_times_vector(A, k, k_eig_values, k_eig_vectors, u):\n",
    "    suma = 0\n",
    "    #Recorremos los valores y vectores, esto son de tamaño k\n",
    "    for i in range(k):\n",
    "        #Extraemos uno por uno los valores y el vector correspondiente a k\n",
    "        lam = k_eig_values[i]\n",
    "        x = k_eig_vectors[i]\n",
    "        #Lo primero que hacemos es multiplicar los valoresen parentesis de v^t * u\n",
    "        multi1 = x*u\n",
    "        #Para la sumatoria guardamos los valores de la iteracion anterior y multiplicamos el valor propio correspondiente\n",
    "        #por el parentesis obtenido anteirormente donde este se multiplica por v.\n",
    "        suma = suma + lam*(multi1*x)\n",
    "        #Entonces para obtener b, multiplicamos A*u y le restamos la suma\n",
    "        b = A*u - suma \n",
    "        #print(b)\n",
    "    # b is the result of the matrix-vector product\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eig_values)\n",
    "print(eig_vectors)\n",
    "print(MatrizSparceA.shape)\n",
    "A_times_vector(MatrizSparceA, k, eig_values, eig_vectors, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (30 puntos)** Implemente la función `sparse_deflation`, modificando su implementación inicial de *Deflation*, que permita operar sobre matrices de gran dimenensión y que sean *sparse*. Para esto, utilice la implementación realizada de la función `A_times_vector` en combinación con el algoritmo de *Power Iteration*. La función `sparse_deflation` recibe como parámetros:\n",
    "* La matriz $A$ de tipo *sparse*.\n",
    "* El *initial guess* $\\mathbf{x}_0$.\n",
    "* El número de iteraciones a realizar en *Power Iteration*\n",
    "* Un número $T$ que indique el número de valores y vectores propios que se desean obtener de la matriz $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute T eigenvalues and eigenvectors from the sparse matrix A, using Deflation.\n",
    "Input:\n",
    "A - (n x n matrix) Sparse matrix\n",
    "x0 - (array) Initial guess for Power Iteration\n",
    "it - (integer) Number of iterations for Power Iteration\n",
    "T - (integer) Number of eigenvalues and eigenvectors to compute from A\n",
    "Output:\n",
    "eig_values - (list) List of T eigenvalues found by the algorithm\n",
    "eig_vectors - (list) List of T eigenvectors found by the algorithm\n",
    "'''\n",
    "def power_iteration2(A, x, k,eig_values ,eig_vectors):\n",
    "    for j in range(k):\n",
    "        u = x/np.linalg.norm(x)\n",
    "        x = A_times_vector(A, k, eig_values, eig_vectors, u) #np.dot(A, u)\n",
    "        lam = np.dot(u, x)\n",
    "    u = x/np.linalg.norm(x)\n",
    "    return (lam, u)  \n",
    "\n",
    "def sparse_deflation(A, x0, it, T):\n",
    "    #Debemos usar la cantidad T de valores y vectores propios.\n",
    "    eig_values = []\n",
    "    eig_vectors = []\n",
    "    for i in range(T):\n",
    "        lam , u =  power_iteration2(A, x0, it,eig_values ,eig_vectors)\n",
    "        eig_values.append(lam)\n",
    "        eig_vectors.append(u)\n",
    "        A = A - np.outer(np.dot(lam,u),u.transpose())\n",
    "    return eig_values, eig_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplique la función `sparse_deflation` sobre las matrices cargadas desde los archivos adjuntos, para distintos valores de $T$ y de iteraciones para *Power Iteration*. Mida los tiempos de ejecución y concluya al respecto. ¿Podría haber aplicado el algoritmo NSI para estas matrices? Justifique y concluya al respecto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta: Cuando mayor es la cantidad de vectores y valores propios mayor es el tiempo de ejecucion, esto debido a que la matriz crece y forma una matriz más grande. Si bien la matriz es sparse, el numero de iteraciones aumenta la cantidad de matrices y se usan 3 algoritmos, lo que produce un tiempo de ejecucion mayor pero este es mas bajo que usar matrices no sparse, debido a que no se realizan calculos innecesarios y la matriz es mas \"pequeña\". Si aplicaramos NSI tendriamos que usar la descomposicion por lo que aumentaria el espacio de memoria necesario y como vimos anteriormente ya es alto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Instrucciones:\n",
    "\n",
    "* **Importante, Asegúrese de responder TODO lo que la pregunta pide.**\n",
    "* La estructura de la tarea es la siguiente:\n",
    "     1. Título, nombre de estudiante, email y rol.\n",
    "     2. Responder cada pregunta de forma personal.\n",
    "     5. Referencias. Es muy importante incluir todas las fuentes usadas, de otra forma se considera que lo no se ha citado adecuadamente es su trabajo.\n",
    "* La tarea debe ser realizada en `Jupyter Notebook` (`Python3`) entregado.\n",
    "* Recuerde responder la encuesta en el plazo establecido\n",
    "* Se evaluará la correcta utilización de librerias `NumPy`, `SciPy`, `Matplotlib` y `ipywidgets`, entre otras, así como la **correcta implementación de algoritmos vectorizados**.\n",
    "* **MUY IMPORTANTE** El archivo de entrega debe denominarse TareaN-rol.tar.gz y _notebook_ debe tener como nombre TareaN-rol.ipynb, donde $N$ es el número de la tarea y debe contener un directorio con todos los archivos necesarios para ejecutar el notebook, junto con un archivo README indicando explícitamente las librerías o módulos utilizados, nombre y rol del estudiante. Por cada error en este ambito implicará un descuento de 30 puntos.\n",
    "* El descuento por día de atraso será de $30$ puntos, con un máximo de 1 día de atraso. No se recibirán entregas después de este día.\n",
    "* Debe citar toda fuente de código externo. \n",
    "* El trabajo es personal, no se permite compartir código ni utilizar código de otros, aunque sí se sugiere discutir aspectos generales con sus compañeros.\n",
    "* En caso de sospecha de no cumplimiento de estas instrucciones, se solicitará al involucrado o la involucrada a aclarar la situación. Dependiendo de la justificación se decidirá su calificación, la cual podrá o no ser penalizada.\n",
    "* El no seguir estas instrucciones, implica descuentos en su nota obtenida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Referencias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[1] Sparse matrix, https://en.wikipedia.org/wiki/Sparse_matrix\n",
    "\n",
    "[2] Sparse module, Scipy. https://docs.scipy.org/doc/scipy/reference/sparse.html\n",
    "[3] Jupyter Notebook Curso. https://github.com/tclaudioe/Scientific-Computing \n",
    "[4] Iteración simultánea y algoritmo de QR. https://www.inf.utfsm.cl/~parce/cc2/clase6-PA.html\n",
    "[5] Sperse Matrix. https://scipy.github.io/devdocs/sparse.html\n",
    "[6] Memory Sparse Matrix. https://cmdlinetips.com/2018/03/sparse-matrices-in-python-with-scipy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
